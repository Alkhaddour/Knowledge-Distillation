{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "isolated-reducing",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "convenient-spyware",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision                import datasets, transforms\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets       import ImageFolder\n",
    "from torch.optim.lr_scheduler   import StepLR\n",
    "from pytorch_model_summary      import summary\n",
    "import torch.utils.data as data\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unusual-respondent",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs     = 50\n",
    "lr         = 0.01\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = \"./CIFAR10\"\n",
    "temperature = 4\n",
    "alpha       = 0.95\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "collaborative-kenya",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "sunset-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "uniform-spring",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acoustic-wonder",
   "metadata": {},
   "source": [
    "### Teacher Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "supreme-enhancement",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output, x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "incomplete-sellers",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = CNN_Net().to(device)\n",
    "teacher.load_state_dict(torch.load('./models/CIFAR10_CNN_teacher.pt'))\n",
    "teacher = teacher.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empty-suite",
   "metadata": {},
   "source": [
    "### Student Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "successful-prague",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class CNN_Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Student, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "            \n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1152, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc_layers(x)\n",
    "        y_pred = F.log_softmax(logits, dim=1)\n",
    "        return y_pred, logits\n",
    "    \n",
    "def distillation_loss(logits_stu, logits_base, T):\n",
    "    logits_stu  = logits_stu  / T\n",
    "    logits_base = logits_base / T\n",
    "    pred_stu    = F.log_softmax(logits_stu,  dim=1)\n",
    "    prop_base   = nn.Softmax(dim=1) (logits_base)\n",
    "    pred_base   = torch.argmax(prop_base, dim=1)\n",
    "    loss        = F.nll_loss(pred_stu, pred_base, reduction='sum')\n",
    "    return loss\n",
    "    \n",
    "def train(model, iterator , optimizer, teacher, device, T, alpha):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0    \n",
    "    model = model.train()\n",
    "    teacher = teacher.eval()\n",
    "    for (x, y) in iterator:        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)        \n",
    "        optimizer.zero_grad()         \n",
    "        if teacher is not None:\n",
    "            y_pred, logits_pred = model(x)        \n",
    "            y_teacher, logits_teacher = teacher(x)\n",
    "            dist_loss = distillation_loss(logits_pred,logits_teacher,T)            \n",
    "            stu_loss  = F.nll_loss(y_pred, y, reduction='sum')     \n",
    "            loss      = alpha * dist_loss + (1-alpha) * stu_loss\n",
    "        else:\n",
    "            y_pred, _ = model(x)        \n",
    "            loss = F.nll_loss(y_pred, y, reduction='sum')   \n",
    "            \n",
    "        acc = calculate_accuracy(y_pred, y)        \n",
    "        loss.backward()        \n",
    "        optimizer.step()        \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
    "\n",
    "def evaluate(model, iterator, device):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()    \n",
    "    with torch.no_grad():        \n",
    "        for (x, y) in iterator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred, _ = model(x)\n",
    "            loss = F.nll_loss(y_pred, y, reduction='sum')\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-reynolds",
   "metadata": {},
   "source": [
    "### Initialize & Define loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "palestinian-occurrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "arbitrary-coffee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of training examples: 50000\n",
      "Number of validation examples: 10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\"CIFAR10\", train=True, download=True, transform=transform_train)\n",
    "valid_data = datasets.CIFAR10(\"CIFAR10\", train=False, transform=transform_test)\n",
    "    \n",
    "#print summary\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "elect-observation",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle= True, pin_memory=True)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "involved-circle",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "flush-spending",
   "metadata": {},
   "outputs": [],
   "source": [
    "#dist_model = CNN_Student().to(device)\n",
    "#optimizer = optim.SGD(dist_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "animal-suggestion",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(f'The model has {count_params(dist_model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "limited-course",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run (T):\n",
    "    best_valid_acc  = 0\n",
    "    dist_model = CNN_Student().to(device)\n",
    "    optimizer = optim.SGD(dist_model.parameters(), lr = lr)\n",
    "\n",
    "    for epoch in range(1, epochs + 1):    \n",
    "        start_time = time.monotonic()\n",
    "        \n",
    "        train_loss, train_acc = train(dist_model, train_loader, optimizer,teacher, device, T, alpha)\n",
    "        valid_loss, valid_acc = evaluate(dist_model, valid_loader, device)\n",
    "\n",
    "        if valid_acc > best_valid_acc:\n",
    "            best_valid_acc  = valid_acc\n",
    "            torch.save(dist_model.state_dict(), './models/CIFAR10_CNN_dist T = ' + str(T)+ '_.pt')\n",
    "\n",
    "        end_time = time.monotonic()\n",
    "\n",
    "        epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "\n",
    "        print(f'Epoch: {epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "        print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "        print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% |  Best Val. Acc: {best_valid_acc*100:.2f}%')\n",
    "\n",
    "    return best_valid_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "rubber-storage",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------- Processing with T = 7.0 --------------------\n",
      "Epoch: 01 | Epoch Time: 0m 21s\n",
      "\tTrain Loss: 107.964 | Train Acc: 41.55%\n",
      "\t Val. Loss: 197.922 |  Val. Acc: 56.48% |  Best Val. Acc: 56.48%\n",
      "Epoch: 02 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 84.786 | Train Acc: 56.34%\n",
      "\t Val. Loss: 189.551 |  Val. Acc: 63.61% |  Best Val. Acc: 63.61%\n",
      "Epoch: 03 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 74.090 | Train Acc: 62.38%\n",
      "\t Val. Loss: 176.124 |  Val. Acc: 67.46% |  Best Val. Acc: 67.46%\n",
      "Epoch: 04 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 67.289 | Train Acc: 65.87%\n",
      "\t Val. Loss: 194.634 |  Val. Acc: 68.20% |  Best Val. Acc: 68.20%\n",
      "Epoch: 05 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 63.371 | Train Acc: 68.05%\n",
      "\t Val. Loss: 233.073 |  Val. Acc: 67.76% |  Best Val. Acc: 68.20%\n",
      "Epoch: 06 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 59.693 | Train Acc: 70.04%\n",
      "\t Val. Loss: 207.873 |  Val. Acc: 69.79% |  Best Val. Acc: 69.79%\n",
      "Epoch: 07 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 57.035 | Train Acc: 71.31%\n",
      "\t Val. Loss: 174.706 |  Val. Acc: 73.66% |  Best Val. Acc: 73.66%\n",
      "Epoch: 08 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 54.504 | Train Acc: 72.53%\n",
      "\t Val. Loss: 184.422 |  Val. Acc: 73.68% |  Best Val. Acc: 73.68%\n",
      "Epoch: 09 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 52.954 | Train Acc: 73.60%\n",
      "\t Val. Loss: 197.219 |  Val. Acc: 72.65% |  Best Val. Acc: 73.68%\n",
      "Epoch: 10 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 51.557 | Train Acc: 73.95%\n",
      "\t Val. Loss: 189.354 |  Val. Acc: 73.47% |  Best Val. Acc: 73.68%\n",
      "Epoch: 11 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 49.910 | Train Acc: 74.81%\n",
      "\t Val. Loss: 155.923 |  Val. Acc: 76.78% |  Best Val. Acc: 76.78%\n",
      "Epoch: 12 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 48.984 | Train Acc: 75.40%\n",
      "\t Val. Loss: 183.668 |  Val. Acc: 74.54% |  Best Val. Acc: 76.78%\n",
      "Epoch: 13 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 47.844 | Train Acc: 76.15%\n",
      "\t Val. Loss: 152.181 |  Val. Acc: 78.33% |  Best Val. Acc: 78.33%\n",
      "Epoch: 14 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 47.002 | Train Acc: 76.36%\n",
      "\t Val. Loss: 153.983 |  Val. Acc: 77.60% |  Best Val. Acc: 78.33%\n",
      "Epoch: 15 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 46.375 | Train Acc: 76.71%\n",
      "\t Val. Loss: 150.728 |  Val. Acc: 78.35% |  Best Val. Acc: 78.35%\n",
      "Epoch: 16 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 45.488 | Train Acc: 77.05%\n",
      "\t Val. Loss: 136.055 |  Val. Acc: 79.05% |  Best Val. Acc: 79.05%\n",
      "Epoch: 17 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 44.866 | Train Acc: 77.53%\n",
      "\t Val. Loss: 152.229 |  Val. Acc: 78.76% |  Best Val. Acc: 79.05%\n",
      "Epoch: 18 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 44.325 | Train Acc: 77.92%\n",
      "\t Val. Loss: 165.119 |  Val. Acc: 78.51% |  Best Val. Acc: 79.05%\n",
      "Epoch: 19 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 43.764 | Train Acc: 78.31%\n",
      "\t Val. Loss: 159.562 |  Val. Acc: 79.31% |  Best Val. Acc: 79.31%\n",
      "Epoch: 20 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 42.813 | Train Acc: 78.24%\n",
      "\t Val. Loss: 150.590 |  Val. Acc: 78.95% |  Best Val. Acc: 79.31%\n",
      "Epoch: 21 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 43.276 | Train Acc: 78.43%\n",
      "\t Val. Loss: 158.651 |  Val. Acc: 78.62% |  Best Val. Acc: 79.31%\n",
      "Epoch: 22 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 42.455 | Train Acc: 78.86%\n",
      "\t Val. Loss: 137.282 |  Val. Acc: 80.50% |  Best Val. Acc: 80.50%\n",
      "Epoch: 23 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 41.523 | Train Acc: 79.11%\n",
      "\t Val. Loss: 160.150 |  Val. Acc: 78.68% |  Best Val. Acc: 80.50%\n",
      "Epoch: 24 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 41.381 | Train Acc: 79.18%\n",
      "\t Val. Loss: 157.880 |  Val. Acc: 78.76% |  Best Val. Acc: 80.50%\n",
      "Epoch: 25 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 40.786 | Train Acc: 79.64%\n",
      "\t Val. Loss: 149.239 |  Val. Acc: 80.24% |  Best Val. Acc: 80.50%\n",
      "Epoch: 26 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 39.891 | Train Acc: 79.98%\n",
      "\t Val. Loss: 149.727 |  Val. Acc: 79.64% |  Best Val. Acc: 80.50%\n",
      "Epoch: 27 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 39.988 | Train Acc: 80.04%\n",
      "\t Val. Loss: 181.841 |  Val. Acc: 77.09% |  Best Val. Acc: 80.50%\n",
      "Epoch: 28 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 39.658 | Train Acc: 80.15%\n",
      "\t Val. Loss: 144.878 |  Val. Acc: 80.14% |  Best Val. Acc: 80.50%\n",
      "Epoch: 29 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 39.804 | Train Acc: 80.03%\n",
      "\t Val. Loss: 142.327 |  Val. Acc: 80.91% |  Best Val. Acc: 80.91%\n",
      "Epoch: 30 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 39.269 | Train Acc: 80.32%\n",
      "\t Val. Loss: 146.629 |  Val. Acc: 80.11% |  Best Val. Acc: 80.91%\n",
      "Epoch: 31 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 38.401 | Train Acc: 80.86%\n",
      "\t Val. Loss: 142.686 |  Val. Acc: 80.90% |  Best Val. Acc: 80.91%\n",
      "Epoch: 32 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 38.312 | Train Acc: 80.94%\n",
      "\t Val. Loss: 156.123 |  Val. Acc: 79.83% |  Best Val. Acc: 80.91%\n",
      "Epoch: 33 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 38.466 | Train Acc: 80.84%\n",
      "\t Val. Loss: 139.428 |  Val. Acc: 81.33% |  Best Val. Acc: 81.33%\n",
      "Epoch: 34 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 37.564 | Train Acc: 81.14%\n",
      "\t Val. Loss: 143.180 |  Val. Acc: 80.93% |  Best Val. Acc: 81.33%\n",
      "Epoch: 35 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 37.626 | Train Acc: 81.07%\n",
      "\t Val. Loss: 157.665 |  Val. Acc: 80.10% |  Best Val. Acc: 81.33%\n",
      "Epoch: 36 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 37.664 | Train Acc: 81.31%\n",
      "\t Val. Loss: 166.978 |  Val. Acc: 79.56% |  Best Val. Acc: 81.33%\n",
      "Epoch: 37 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 37.249 | Train Acc: 81.44%\n",
      "\t Val. Loss: 152.363 |  Val. Acc: 80.55% |  Best Val. Acc: 81.33%\n",
      "Epoch: 38 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 37.100 | Train Acc: 81.50%\n",
      "\t Val. Loss: 192.265 |  Val. Acc: 78.96% |  Best Val. Acc: 81.33%\n",
      "Epoch: 39 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 36.678 | Train Acc: 81.71%\n",
      "\t Val. Loss: 152.057 |  Val. Acc: 80.87% |  Best Val. Acc: 81.33%\n",
      "Epoch: 40 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 36.546 | Train Acc: 81.73%\n",
      "\t Val. Loss: 154.998 |  Val. Acc: 81.37% |  Best Val. Acc: 81.37%\n",
      "Epoch: 41 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 36.057 | Train Acc: 81.95%\n",
      "\t Val. Loss: 148.279 |  Val. Acc: 81.09% |  Best Val. Acc: 81.37%\n",
      "Epoch: 42 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 35.982 | Train Acc: 82.13%\n",
      "\t Val. Loss: 137.401 |  Val. Acc: 82.08% |  Best Val. Acc: 82.08%\n",
      "Epoch: 43 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 35.931 | Train Acc: 82.11%\n",
      "\t Val. Loss: 157.312 |  Val. Acc: 80.53% |  Best Val. Acc: 82.08%\n",
      "Epoch: 44 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 35.474 | Train Acc: 82.41%\n",
      "\t Val. Loss: 153.883 |  Val. Acc: 81.01% |  Best Val. Acc: 82.08%\n",
      "Epoch: 45 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 35.800 | Train Acc: 82.33%\n",
      "\t Val. Loss: 146.126 |  Val. Acc: 81.23% |  Best Val. Acc: 82.08%\n",
      "Epoch: 46 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 35.265 | Train Acc: 82.55%\n",
      "\t Val. Loss: 151.684 |  Val. Acc: 81.60% |  Best Val. Acc: 82.08%\n",
      "Epoch: 47 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 35.372 | Train Acc: 82.42%\n",
      "\t Val. Loss: 154.055 |  Val. Acc: 81.32% |  Best Val. Acc: 82.08%\n",
      "Epoch: 48 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 34.931 | Train Acc: 82.68%\n",
      "\t Val. Loss: 171.263 |  Val. Acc: 80.23% |  Best Val. Acc: 82.08%\n",
      "Epoch: 49 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 34.760 | Train Acc: 82.80%\n",
      "\t Val. Loss: 145.289 |  Val. Acc: 81.36% |  Best Val. Acc: 82.08%\n",
      "Epoch: 50 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 34.624 | Train Acc: 82.85%\n",
      "\t Val. Loss: 143.380 |  Val. Acc: 81.82% |  Best Val. Acc: 82.08%\n"
     ]
    }
   ],
   "source": [
    "Ts  = [7.0] #[4.0, 5.0, 6.0, 7.0, 8.0, 10.0, 15.0, 20.0]\n",
    "acc = []\n",
    "\n",
    "for temperature in Ts:\n",
    "    print (f\"-------------------- Processing with T = {temperature} --------------------\")\n",
    "    acc.append(run(temperature))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "requested-virginia",
   "metadata": {},
   "source": [
    "### Load and re-run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "reflected-survey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Val. Loss: 137.401 |  Val. Acc: 82.08%\n"
     ]
    }
   ],
   "source": [
    "dist_model = CNN_Student().to(device)\n",
    "dist_model.load_state_dict(torch.load('./models/CIFAR10_CNN_dist T = 7.0_.pt'))\n",
    "valid_loss, valid_acc = evaluate(dist_model, valid_loader, device)\n",
    "print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dressed-haiti",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
