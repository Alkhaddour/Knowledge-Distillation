{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CHadwpvmREvE"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision                import datasets, transforms\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets       import ImageFolder\n",
    "from torch.optim.lr_scheduler   import StepLR\n",
    "from pytorch_model_summary      import summary\n",
    "import torch.utils.data as data\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs     = 50\n",
    "lr         = 0.01\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = \"./CIFAR10\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lAqzcW9XREvu"
   },
   "outputs": [],
   "source": [
    "class CNN_Student(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Student, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=32, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "\n",
    "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.MaxPool2d(kernel_size=3, stride=3),\n",
    "            \n",
    "        nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.ReLU(inplace=True),\n",
    "            \n",
    "        nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1152, 10))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        logits = self.fc_layers(x)\n",
    "        y_pred = F.log_softmax(logits, dim=1)\n",
    "        return y_pred, logits\n",
    "\n",
    "def train(model, train_loader, optimizer, device):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0    \n",
    "    model.train()    \n",
    "    for (x, y) in train_loader:        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)        \n",
    "        optimizer.zero_grad()                \n",
    "        y_pred, _ = model(x)        \n",
    "        loss = F.nll_loss(y_pred, y, reduction='sum')        \n",
    "        acc = calculate_accuracy(y_pred, y)        \n",
    "        loss.backward()        \n",
    "        optimizer.step()            \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n",
    "\n",
    "def evaluate(model, iterator, device):\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()    \n",
    "    with torch.no_grad():        \n",
    "        for (x, y) in iterator:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred, _ = model(x)\n",
    "            loss = F.nll_loss(y_pred, y, reduction='sum')\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()        \n",
    "    return epoch_loss / len(iterator), epoch_acc / len(iterator)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize & Define loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WuYq4cRdREvV"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding = 5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of training examples: 50000\n",
      "Number of validation examples: 10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\"CIFAR10\", train=True, download=True, transform=transform_train)\n",
    "valid_data = datasets.CIFAR10(\"CIFAR10\", train=False, transform=transform_test)\n",
    "    \n",
    "#print summary\n",
    "print(f'Number of training examples: {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle= True, pin_memory=True)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3Ew0aobVREv0"
   },
   "outputs": [],
   "source": [
    "student_model = CNN_Student().to(device)\n",
    "optimizer = optim.SGD(student_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "8N1iy4Sji4jl",
    "outputId": "753725c3-7394-4254-f8ca-073dc08648ac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 139,338 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_params(student_model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Student"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_acc  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 557
    },
    "colab_type": "code",
    "id": "p-gtfzafREwc",
    "outputId": "a1314661-c18c-4de6-d6f5-89541165199e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 138.320 | Train Acc: 22.91%\n",
      "\t Val. Loss: 113.878 |  Val. Acc: 35.10% |  Best Val. Acc: 35.10%\n",
      "Epoch: 02 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 117.081 | Train Acc: 32.43%\n",
      "\t Val. Loss: 105.936 |  Val. Acc: 38.38% |  Best Val. Acc: 38.38%\n",
      "Epoch: 03 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 111.135 | Train Acc: 35.19%\n",
      "\t Val. Loss: 97.364 |  Val. Acc: 43.09% |  Best Val. Acc: 43.09%\n",
      "Epoch: 04 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 105.785 | Train Acc: 38.44%\n",
      "\t Val. Loss: 118.375 |  Val. Acc: 36.82% |  Best Val. Acc: 43.09%\n",
      "Epoch: 05 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 99.577 | Train Acc: 42.65%\n",
      "\t Val. Loss: 88.782 |  Val. Acc: 48.02% |  Best Val. Acc: 48.02%\n",
      "Epoch: 06 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 94.694 | Train Acc: 46.18%\n",
      "\t Val. Loss: 92.545 |  Val. Acc: 47.93% |  Best Val. Acc: 48.02%\n",
      "Epoch: 07 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 90.437 | Train Acc: 49.02%\n",
      "\t Val. Loss: 92.123 |  Val. Acc: 49.61% |  Best Val. Acc: 49.61%\n",
      "Epoch: 08 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 87.283 | Train Acc: 50.66%\n",
      "\t Val. Loss: 74.035 |  Val. Acc: 57.22% |  Best Val. Acc: 57.22%\n",
      "Epoch: 09 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 84.637 | Train Acc: 52.47%\n",
      "\t Val. Loss: 77.810 |  Val. Acc: 55.27% |  Best Val. Acc: 57.22%\n",
      "Epoch: 10 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 81.801 | Train Acc: 54.59%\n",
      "\t Val. Loss: 81.325 |  Val. Acc: 54.40% |  Best Val. Acc: 57.22%\n",
      "Epoch: 11 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 79.196 | Train Acc: 55.76%\n",
      "\t Val. Loss: 68.976 |  Val. Acc: 62.12% |  Best Val. Acc: 62.12%\n",
      "Epoch: 12 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 76.312 | Train Acc: 57.65%\n",
      "\t Val. Loss: 68.909 |  Val. Acc: 62.48% |  Best Val. Acc: 62.48%\n",
      "Epoch: 13 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 73.746 | Train Acc: 59.50%\n",
      "\t Val. Loss: 69.546 |  Val. Acc: 62.65% |  Best Val. Acc: 62.65%\n",
      "Epoch: 14 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 71.995 | Train Acc: 60.41%\n",
      "\t Val. Loss: 69.857 |  Val. Acc: 61.06% |  Best Val. Acc: 62.65%\n",
      "Epoch: 15 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 70.909 | Train Acc: 61.03%\n",
      "\t Val. Loss: 64.008 |  Val. Acc: 64.99% |  Best Val. Acc: 64.99%\n",
      "Epoch: 16 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 69.007 | Train Acc: 62.25%\n",
      "\t Val. Loss: 64.104 |  Val. Acc: 65.89% |  Best Val. Acc: 65.89%\n",
      "Epoch: 17 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 67.901 | Train Acc: 62.95%\n",
      "\t Val. Loss: 60.001 |  Val. Acc: 66.94% |  Best Val. Acc: 66.94%\n",
      "Epoch: 18 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 67.041 | Train Acc: 63.43%\n",
      "\t Val. Loss: 59.677 |  Val. Acc: 68.22% |  Best Val. Acc: 68.22%\n",
      "Epoch: 19 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 65.818 | Train Acc: 64.07%\n",
      "\t Val. Loss: 58.421 |  Val. Acc: 67.76% |  Best Val. Acc: 68.22%\n",
      "Epoch: 20 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 64.462 | Train Acc: 64.80%\n",
      "\t Val. Loss: 56.360 |  Val. Acc: 69.55% |  Best Val. Acc: 69.55%\n",
      "Epoch: 21 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 63.704 | Train Acc: 65.46%\n",
      "\t Val. Loss: 60.271 |  Val. Acc: 67.82% |  Best Val. Acc: 69.55%\n",
      "Epoch: 22 | Epoch Time: 0m 18s\n",
      "\tTrain Loss: 62.804 | Train Acc: 65.73%\n",
      "\t Val. Loss: 58.301 |  Val. Acc: 68.93% |  Best Val. Acc: 69.55%\n",
      "Epoch: 23 | Epoch Time: 0m 19s\n",
      "\tTrain Loss: 62.140 | Train Acc: 66.05%\n",
      "\t Val. Loss: 59.465 |  Val. Acc: 69.99% |  Best Val. Acc: 69.99%\n",
      "Epoch: 24 | Epoch Time: 0m 18s\n",
      "\tTrain Loss: 61.085 | Train Acc: 66.59%\n",
      "\t Val. Loss: 57.578 |  Val. Acc: 68.69% |  Best Val. Acc: 69.99%\n",
      "Epoch: 25 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 60.315 | Train Acc: 67.21%\n",
      "\t Val. Loss: 53.838 |  Val. Acc: 70.51% |  Best Val. Acc: 70.51%\n",
      "Epoch: 26 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 59.736 | Train Acc: 67.63%\n",
      "\t Val. Loss: 60.464 |  Val. Acc: 68.60% |  Best Val. Acc: 70.51%\n",
      "Epoch: 27 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 58.626 | Train Acc: 68.09%\n",
      "\t Val. Loss: 63.671 |  Val. Acc: 67.04% |  Best Val. Acc: 70.51%\n",
      "Epoch: 28 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 58.630 | Train Acc: 68.19%\n",
      "\t Val. Loss: 54.457 |  Val. Acc: 71.61% |  Best Val. Acc: 71.61%\n",
      "Epoch: 29 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 57.588 | Train Acc: 68.73%\n",
      "\t Val. Loss: 52.744 |  Val. Acc: 72.74% |  Best Val. Acc: 72.74%\n",
      "Epoch: 30 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 57.356 | Train Acc: 69.18%\n",
      "\t Val. Loss: 57.140 |  Val. Acc: 70.60% |  Best Val. Acc: 72.74%\n",
      "Epoch: 31 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 56.230 | Train Acc: 69.40%\n",
      "\t Val. Loss: 55.796 |  Val. Acc: 71.07% |  Best Val. Acc: 72.74%\n",
      "Epoch: 32 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 55.842 | Train Acc: 69.67%\n",
      "\t Val. Loss: 53.777 |  Val. Acc: 72.41% |  Best Val. Acc: 72.74%\n",
      "Epoch: 33 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 55.340 | Train Acc: 70.11%\n",
      "\t Val. Loss: 51.840 |  Val. Acc: 73.51% |  Best Val. Acc: 73.51%\n",
      "Epoch: 34 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 55.111 | Train Acc: 70.05%\n",
      "\t Val. Loss: 55.929 |  Val. Acc: 71.38% |  Best Val. Acc: 73.51%\n",
      "Epoch: 35 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 54.686 | Train Acc: 70.50%\n",
      "\t Val. Loss: 51.600 |  Val. Acc: 72.84% |  Best Val. Acc: 73.51%\n",
      "Epoch: 36 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 54.453 | Train Acc: 70.37%\n",
      "\t Val. Loss: 49.720 |  Val. Acc: 73.67% |  Best Val. Acc: 73.67%\n",
      "Epoch: 37 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 53.999 | Train Acc: 70.65%\n",
      "\t Val. Loss: 50.444 |  Val. Acc: 73.49% |  Best Val. Acc: 73.67%\n",
      "Epoch: 38 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 53.815 | Train Acc: 70.94%\n",
      "\t Val. Loss: 49.609 |  Val. Acc: 74.27% |  Best Val. Acc: 74.27%\n",
      "Epoch: 39 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 52.859 | Train Acc: 71.66%\n",
      "\t Val. Loss: 48.901 |  Val. Acc: 74.44% |  Best Val. Acc: 74.44%\n",
      "Epoch: 40 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 53.089 | Train Acc: 71.34%\n",
      "\t Val. Loss: 50.740 |  Val. Acc: 73.65% |  Best Val. Acc: 74.44%\n",
      "Epoch: 41 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 52.614 | Train Acc: 71.63%\n",
      "\t Val. Loss: 51.071 |  Val. Acc: 72.99% |  Best Val. Acc: 74.44%\n",
      "Epoch: 42 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 51.723 | Train Acc: 71.96%\n",
      "\t Val. Loss: 50.597 |  Val. Acc: 73.56% |  Best Val. Acc: 74.44%\n",
      "Epoch: 43 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 51.876 | Train Acc: 71.92%\n",
      "\t Val. Loss: 48.348 |  Val. Acc: 74.65% |  Best Val. Acc: 74.65%\n",
      "Epoch: 44 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 51.547 | Train Acc: 72.28%\n",
      "\t Val. Loss: 50.079 |  Val. Acc: 73.72% |  Best Val. Acc: 74.65%\n",
      "Epoch: 45 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 51.212 | Train Acc: 72.39%\n",
      "\t Val. Loss: 47.985 |  Val. Acc: 74.70% |  Best Val. Acc: 74.70%\n",
      "Epoch: 46 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 51.009 | Train Acc: 72.42%\n",
      "\t Val. Loss: 49.505 |  Val. Acc: 73.93% |  Best Val. Acc: 74.70%\n",
      "Epoch: 47 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 50.642 | Train Acc: 72.56%\n",
      "\t Val. Loss: 48.801 |  Val. Acc: 73.84% |  Best Val. Acc: 74.70%\n",
      "Epoch: 48 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 50.097 | Train Acc: 72.77%\n",
      "\t Val. Loss: 47.571 |  Val. Acc: 74.65% |  Best Val. Acc: 74.70%\n",
      "Epoch: 49 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 50.334 | Train Acc: 72.63%\n",
      "\t Val. Loss: 47.003 |  Val. Acc: 74.78% |  Best Val. Acc: 74.78%\n",
      "Epoch: 50 | Epoch Time: 0m 17s\n",
      "\tTrain Loss: 49.635 | Train Acc: 73.21%\n",
      "\t Val. Loss: 53.348 |  Val. Acc: 73.88% |  Best Val. Acc: 74.78%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(student_model, train_loader, optimizer, device)\n",
    "    valid_loss, valid_acc = evaluate(student_model, valid_loader, device)\n",
    "    \n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc  = valid_acc\n",
    "        torch.save(student_model.state_dict(), './models/CIFAR10_CNN_student.pt')\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% |  Best Val. Acc: {best_valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and re-run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Val. Loss: 47.003 |  Val. Acc: 74.78% |  Best Val. Acc: 74.78%\n"
     ]
    }
   ],
   "source": [
    "student_model.load_state_dict(torch.load('./models/CIFAR10_CNN_student.pt'))\n",
    "valid_loss, valid_acc = evaluate(student_model, valid_loader, device)\n",
    "print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% |  Best Val. Acc: {best_valid_acc*100:.2f}%')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "1 - Multilayer Perceptron.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
