{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "flush-indian",
   "metadata": {},
   "source": [
    "### Load Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "copyrighted-bunny",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision                import datasets, transforms\n",
    "from torchvision.datasets.utils import download_url\n",
    "from torchvision.datasets       import ImageFolder\n",
    "from torch.optim.lr_scheduler   import StepLR\n",
    "from pytorch_model_summary      import summary\n",
    "import torch.utils.data as data\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "productive-cruise",
   "metadata": {},
   "source": [
    "### Define params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "billion-romania",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "batch_size = 64\n",
    "epochs     = 50\n",
    "lr         = 0.01\n",
    "device     = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "data_path = \"./CIFAR10\"\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "laughing-pride",
   "metadata": {},
   "source": [
    "### Some utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "magnetic-martin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_params(model):\n",
    "    return sum(p.numel() for p in model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "developing-repair",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "strong-allergy",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_accuracy(y_pred, y):\n",
    "    top_pred = y_pred.argmax(1, keepdim = True)\n",
    "    correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
    "    acc = correct.float() / y.shape[0]\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-drink",
   "metadata": {},
   "source": [
    "### define network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "corresponding-wilderness",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN_Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN_Net, self).__init__()\n",
    "        self.conv_layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            \n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=256, out_channels=512, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(1024),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.fc_layers = nn.Sequential(\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.ReLU(inplace=True),\n",
    "            \n",
    "            nn.Linear(512, 10)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc_layers(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output, x\n",
    "\n",
    "\n",
    "def train(model, train_loader, optimizer, device):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0    \n",
    "    model.train()    \n",
    "    for (x, y) in train_loader:        \n",
    "        x = x.to(device)\n",
    "        y = y.to(device)        \n",
    "        optimizer.zero_grad()                \n",
    "        y_pred, _ = model(x)        \n",
    "        loss = F.nll_loss(y_pred, y, reduction='mean')        \n",
    "        acc = calculate_accuracy(y_pred, y)        \n",
    "        loss.backward()        \n",
    "        optimizer.step()     \n",
    "       \n",
    "        epoch_loss += loss.item()\n",
    "        epoch_acc += acc.item()\n",
    "    \n",
    "    return epoch_loss / len(train_loader), epoch_acc / len(train_loader)\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device):    \n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    model.eval()    \n",
    "    with torch.no_grad():        \n",
    "        for (x, y) in test_loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            y_pred, _ = model(x)\n",
    "            loss = F.nll_loss(y_pred, y, reduction='sum')\n",
    "            acc = calculate_accuracy(y_pred, y)\n",
    "            epoch_loss += loss.item()\n",
    "            epoch_acc += acc.item()        \n",
    "    return epoch_loss / len(test_loader), epoch_acc / len(test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "blocked-strength",
   "metadata": {},
   "source": [
    "### Initialize & Define loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "gorgeous-absolute",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding = 5),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "possible-blend",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Number of training examples:   50000\n",
      "Number of validation examples: 10000\n"
     ]
    }
   ],
   "source": [
    "train_data = datasets.CIFAR10(\"CIFAR10\", train=True, download=True, transform=transform_train)\n",
    "valid_data = datasets.CIFAR10(\"CIFAR10\", train=False, transform=transform_test)\n",
    "    \n",
    "#print summary\n",
    "print(f'Number of training examples:   {len(train_data)}')\n",
    "print(f'Number of validation examples: {len(valid_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "divided-evidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader  = torch.utils.data.DataLoader(train_data, batch_size = batch_size, shuffle= True, pin_memory=True)\n",
    "valid_loader  = torch.utils.data.DataLoader(valid_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "significant-tension",
   "metadata": {},
   "source": [
    "### Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "early-pastor",
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_model = CNN_Net().to(device)\n",
    "optimizer = optim.SGD(teacher_model.parameters(), lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "frank-pride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 6,822,154 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "print(f'The model has {count_params(teacher_model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-buddy",
   "metadata": {},
   "source": [
    "### Train Teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "honey-angola",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_valid_acc  = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "compact-flash",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 01 | Epoch Time: 0m 30s\n",
      "\tTrain Loss: 1.471 | Train Acc: 46.13%\n",
      "\t Val. Loss: 81.776 |  Val. Acc: 53.98% |  Best Val. Acc: 53.98%\n",
      "Epoch: 02 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 1.095 | Train Acc: 60.62%\n",
      "\t Val. Loss: 87.091 |  Val. Acc: 53.29% |  Best Val. Acc: 53.98%\n",
      "Epoch: 03 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.919 | Train Acc: 67.33%\n",
      "\t Val. Loss: 67.519 |  Val. Acc: 63.82% |  Best Val. Acc: 63.82%\n",
      "Epoch: 04 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.819 | Train Acc: 70.98%\n",
      "\t Val. Loss: 53.725 |  Val. Acc: 70.52% |  Best Val. Acc: 70.52%\n",
      "Epoch: 05 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.746 | Train Acc: 73.61%\n",
      "\t Val. Loss: 56.125 |  Val. Acc: 69.52% |  Best Val. Acc: 70.52%\n",
      "Epoch: 06 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.689 | Train Acc: 75.96%\n",
      "\t Val. Loss: 64.995 |  Val. Acc: 67.66% |  Best Val. Acc: 70.52%\n",
      "Epoch: 07 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.648 | Train Acc: 77.42%\n",
      "\t Val. Loss: 50.372 |  Val. Acc: 72.97% |  Best Val. Acc: 72.97%\n",
      "Epoch: 08 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.611 | Train Acc: 78.69%\n",
      "\t Val. Loss: 55.149 |  Val. Acc: 70.89% |  Best Val. Acc: 72.97%\n",
      "Epoch: 09 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.582 | Train Acc: 79.72%\n",
      "\t Val. Loss: 47.482 |  Val. Acc: 74.42% |  Best Val. Acc: 74.42%\n",
      "Epoch: 10 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.552 | Train Acc: 80.77%\n",
      "\t Val. Loss: 35.971 |  Val. Acc: 80.78% |  Best Val. Acc: 80.78%\n",
      "Epoch: 11 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.525 | Train Acc: 81.63%\n",
      "\t Val. Loss: 46.246 |  Val. Acc: 75.58% |  Best Val. Acc: 80.78%\n",
      "Epoch: 12 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.509 | Train Acc: 82.15%\n",
      "\t Val. Loss: 43.322 |  Val. Acc: 77.13% |  Best Val. Acc: 80.78%\n",
      "Epoch: 13 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.487 | Train Acc: 83.11%\n",
      "\t Val. Loss: 38.535 |  Val. Acc: 79.06% |  Best Val. Acc: 80.78%\n",
      "Epoch: 14 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.465 | Train Acc: 83.83%\n",
      "\t Val. Loss: 36.331 |  Val. Acc: 80.18% |  Best Val. Acc: 80.78%\n",
      "Epoch: 15 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.450 | Train Acc: 84.27%\n",
      "\t Val. Loss: 39.105 |  Val. Acc: 78.94% |  Best Val. Acc: 80.78%\n",
      "Epoch: 16 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.434 | Train Acc: 84.73%\n",
      "\t Val. Loss: 40.820 |  Val. Acc: 79.07% |  Best Val. Acc: 80.78%\n",
      "Epoch: 17 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.425 | Train Acc: 85.22%\n",
      "\t Val. Loss: 47.714 |  Val. Acc: 76.25% |  Best Val. Acc: 80.78%\n",
      "Epoch: 18 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.405 | Train Acc: 85.83%\n",
      "\t Val. Loss: 42.865 |  Val. Acc: 78.12% |  Best Val. Acc: 80.78%\n",
      "Epoch: 19 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.391 | Train Acc: 86.46%\n",
      "\t Val. Loss: 33.678 |  Val. Acc: 81.87% |  Best Val. Acc: 81.87%\n",
      "Epoch: 20 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.383 | Train Acc: 86.56%\n",
      "\t Val. Loss: 38.737 |  Val. Acc: 79.39% |  Best Val. Acc: 81.87%\n",
      "Epoch: 21 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.370 | Train Acc: 86.94%\n",
      "\t Val. Loss: 34.021 |  Val. Acc: 82.03% |  Best Val. Acc: 82.03%\n",
      "Epoch: 22 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.357 | Train Acc: 87.58%\n",
      "\t Val. Loss: 38.050 |  Val. Acc: 80.66% |  Best Val. Acc: 82.03%\n",
      "Epoch: 23 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.351 | Train Acc: 87.94%\n",
      "\t Val. Loss: 31.641 |  Val. Acc: 83.29% |  Best Val. Acc: 83.29%\n",
      "Epoch: 24 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.340 | Train Acc: 88.09%\n",
      "\t Val. Loss: 33.164 |  Val. Acc: 82.92% |  Best Val. Acc: 83.29%\n",
      "Epoch: 25 | Epoch Time: 0m 28s\n",
      "\tTrain Loss: 0.327 | Train Acc: 88.58%\n",
      "\t Val. Loss: 30.678 |  Val. Acc: 84.75% |  Best Val. Acc: 84.75%\n",
      "Epoch: 26 | Epoch Time: 0m 29s\n",
      "\tTrain Loss: 0.321 | Train Acc: 88.70%\n",
      "\t Val. Loss: 53.200 |  Val. Acc: 76.41% |  Best Val. Acc: 84.75%\n",
      "Epoch: 27 | Epoch Time: 0m 29s\n",
      "\tTrain Loss: 0.313 | Train Acc: 88.94%\n",
      "\t Val. Loss: 30.570 |  Val. Acc: 84.29% |  Best Val. Acc: 84.75%\n",
      "Epoch: 28 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.305 | Train Acc: 89.27%\n",
      "\t Val. Loss: 36.884 |  Val. Acc: 82.22% |  Best Val. Acc: 84.75%\n",
      "Epoch: 29 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.302 | Train Acc: 89.45%\n",
      "\t Val. Loss: 31.820 |  Val. Acc: 83.56% |  Best Val. Acc: 84.75%\n",
      "Epoch: 30 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.287 | Train Acc: 89.89%\n",
      "\t Val. Loss: 35.421 |  Val. Acc: 81.98% |  Best Val. Acc: 84.75%\n",
      "Epoch: 31 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.279 | Train Acc: 90.22%\n",
      "\t Val. Loss: 31.934 |  Val. Acc: 83.84% |  Best Val. Acc: 84.75%\n",
      "Epoch: 32 | Epoch Time: 0m 28s\n",
      "\tTrain Loss: 0.275 | Train Acc: 90.43%\n",
      "\t Val. Loss: 35.253 |  Val. Acc: 82.57% |  Best Val. Acc: 84.75%\n",
      "Epoch: 33 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.266 | Train Acc: 90.50%\n",
      "\t Val. Loss: 30.584 |  Val. Acc: 84.75% |  Best Val. Acc: 84.75%\n",
      "Epoch: 34 | Epoch Time: 0m 25s\n",
      "\tTrain Loss: 0.260 | Train Acc: 90.83%\n",
      "\t Val. Loss: 30.516 |  Val. Acc: 84.70% |  Best Val. Acc: 84.75%\n",
      "Epoch: 35 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.254 | Train Acc: 91.18%\n",
      "\t Val. Loss: 38.573 |  Val. Acc: 82.29% |  Best Val. Acc: 84.75%\n",
      "Epoch: 36 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.251 | Train Acc: 91.17%\n",
      "\t Val. Loss: 26.474 |  Val. Acc: 86.35% |  Best Val. Acc: 86.35%\n",
      "Epoch: 37 | Epoch Time: 0m 28s\n",
      "\tTrain Loss: 0.244 | Train Acc: 91.43%\n",
      "\t Val. Loss: 30.435 |  Val. Acc: 84.26% |  Best Val. Acc: 86.35%\n",
      "Epoch: 38 | Epoch Time: 0m 28s\n",
      "\tTrain Loss: 0.236 | Train Acc: 91.65%\n",
      "\t Val. Loss: 28.059 |  Val. Acc: 86.23% |  Best Val. Acc: 86.35%\n",
      "Epoch: 39 | Epoch Time: 0m 26s\n",
      "\tTrain Loss: 0.231 | Train Acc: 91.94%\n",
      "\t Val. Loss: 31.323 |  Val. Acc: 84.23% |  Best Val. Acc: 86.35%\n",
      "Epoch: 40 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.224 | Train Acc: 92.21%\n",
      "\t Val. Loss: 26.294 |  Val. Acc: 87.31% |  Best Val. Acc: 87.31%\n",
      "Epoch: 41 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.225 | Train Acc: 92.02%\n",
      "\t Val. Loss: 27.926 |  Val. Acc: 86.25% |  Best Val. Acc: 87.31%\n",
      "Epoch: 42 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.215 | Train Acc: 92.49%\n",
      "\t Val. Loss: 42.253 |  Val. Acc: 81.05% |  Best Val. Acc: 87.31%\n",
      "Epoch: 43 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.209 | Train Acc: 92.68%\n",
      "\t Val. Loss: 29.002 |  Val. Acc: 85.80% |  Best Val. Acc: 87.31%\n",
      "Epoch: 44 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.209 | Train Acc: 92.77%\n",
      "\t Val. Loss: 27.841 |  Val. Acc: 86.71% |  Best Val. Acc: 87.31%\n",
      "Epoch: 45 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.202 | Train Acc: 92.75%\n",
      "\t Val. Loss: 34.079 |  Val. Acc: 84.40% |  Best Val. Acc: 87.31%\n",
      "Epoch: 46 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.193 | Train Acc: 93.13%\n",
      "\t Val. Loss: 38.813 |  Val. Acc: 82.52% |  Best Val. Acc: 87.31%\n",
      "Epoch: 47 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.195 | Train Acc: 93.06%\n",
      "\t Val. Loss: 26.969 |  Val. Acc: 86.96% |  Best Val. Acc: 87.31%\n",
      "Epoch: 48 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.189 | Train Acc: 93.16%\n",
      "\t Val. Loss: 27.791 |  Val. Acc: 86.53% |  Best Val. Acc: 87.31%\n",
      "Epoch: 49 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.185 | Train Acc: 93.31%\n",
      "\t Val. Loss: 26.451 |  Val. Acc: 87.17% |  Best Val. Acc: 87.31%\n",
      "Epoch: 50 | Epoch Time: 0m 27s\n",
      "\tTrain Loss: 0.180 | Train Acc: 93.60%\n",
      "\t Val. Loss: 42.338 |  Val. Acc: 81.85% |  Best Val. Acc: 87.31%\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, epochs + 1):    \n",
    "    start_time = time.monotonic()\n",
    "    \n",
    "    train_loss, train_acc = train(teacher_model, train_loader, optimizer, device)\n",
    "    valid_loss, valid_acc = evaluate(teacher_model, valid_loader, device)\n",
    "    \n",
    "    if valid_acc > best_valid_acc:\n",
    "        best_valid_acc  = valid_acc\n",
    "        torch.save(teacher_model.state_dict(), './models/CIFAR10_CNN_teacher.pt')\n",
    "    \n",
    "    end_time = time.monotonic()\n",
    "\n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    print(f'Epoch: {epoch:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}% |  Best Val. Acc: {best_valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "indirect-midnight",
   "metadata": {},
   "source": [
    "### Load and re-run tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "perfect-socket",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Val. Loss: 26.294 |  Val. Acc: 87.31%\n"
     ]
    }
   ],
   "source": [
    "teacher_model.load_state_dict(torch.load('./models/CIFAR10_CNN_teacher.pt'))\n",
    "valid_loss, valid_acc = evaluate(teacher_model, valid_loader, device)\n",
    "print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tired-floor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
